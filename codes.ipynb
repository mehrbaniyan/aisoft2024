{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFrw4Jhhvol3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Step 1: Load and preprocess the CIFAR-10 dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize with mean and std deviation for RGB channels\n",
        "])\n",
        "\n",
        "# Download CIFAR-10 train and test datasets\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Create data loaders\n",
        "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "testloader = DataLoader(testset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Step 2: Define the MLP model with Dense Layers\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "\n",
        "        # Input size is 3*32*32 = 3072\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        # Define fully connected (dense) layers\n",
        "        self.fc1 = nn.Linear(3 * 32 * 32, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 512)\n",
        "        self.fc3 = nn.Linear(512, 256)\n",
        "        self.fc4 = nn.Linear(256, 128)\n",
        "        self.fc5 = nn.Linear(128, 10)            # Output layer for 10 classes\n",
        "\n",
        "        # Activation function\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # Dropout layer to prevent overfitting\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Flatten the input tensor\n",
        "        x = self.flatten(x)\n",
        "\n",
        "        # Pass through first dense layer and activation\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # Pass through second dense layer and activation\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # Pass through third dense layer and activation\n",
        "        x = self.relu(self.fc3(x))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # Pass through fourth dense layer and activation\n",
        "        x = self.relu(self.fc4(x))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # Output layer (no activation, as CrossEntropyLoss applies Softmax)\n",
        "        x = self.fc5(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Step 3: Instantiate the model, define the loss function, and the optimizer\n",
        "model = MLP()\n",
        "\n",
        "# Check if CUDA is available and use GPU if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Loss function (CrossEntropyLoss for multi-class classification)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer (Adam optimizer is often a good choice for dense networks)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Step 4: Train the model\n",
        "num_epochs = 10  # Increased number of epochs for dense networks\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    model.train()  # Set model to training mode\n",
        "    for i, data in enumerate(trainloader, 0):  # Loop over the training data\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass: compute predicted outputs by passing inputs to the model\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass: compute gradients of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Update the model's parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print statistics (every 100 mini-batches)\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:\n",
        "            print(f\"[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 100:.3f}\")\n",
        "            running_loss = 0.0\n",
        "\n",
        "    # Optional: Validate after each epoch\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)  # Get the predicted class\n",
        "            total += labels.size(0)  # Total number of samples\n",
        "            correct += (predicted == labels).sum().item()  # Number of correct predictions\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Epoch {epoch + 1} Validation Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "print(\"Finished Training\")\n",
        "\n",
        "# Step 5: Test the model on the test set\n",
        "model.eval()  # Set model to evaluation mode\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# Turn off gradients for testing\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)  # Get the predicted class\n",
        "        total += labels.size(0)  # Total number of samples\n",
        "        correct += (predicted == labels).sum().item()  # Number of correct predictions\n",
        "\n",
        "print(f\"Accuracy of the network on the 10000 test images: {100 * correct / total:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmQO5ZP4ZdCo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Step 1: Load and preprocess the CIFAR-10 dataset\n",
        "# We will normalize the images and apply transformations\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert image to tensor\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize with mean and std deviation for RGB channels\n",
        "])\n",
        "\n",
        "# Download CIFAR-10 train and test datasets\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Create data loaders\n",
        "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "testloader = DataLoader(testset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Step 2: Define the CNN model\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "\n",
        "        # First convolutional layer\n",
        "        self.conv1 = nn.Conv2d(in_channels=3,  # Input channels (RGB)\n",
        "                               out_channels=16,  # Output channels (number of filters)\n",
        "                               kernel_size=3,  # Size of the convolutional kernel/filter\n",
        "                               stride=1,  # Step size for sliding the filter\n",
        "                               padding=1)  # Padding to maintain image size\n",
        "\n",
        "        # Second convolutional layer\n",
        "        self.conv2 = nn.Conv2d(in_channels=16,  # Input channels (from previous layer)\n",
        "                               out_channels=32,  # Output channels (number of filters)\n",
        "                               kernel_size=3,  # Size of the convolutional kernel/filter\n",
        "                               stride=1,  # Step size for sliding the filter\n",
        "                               padding=1)  # Padding to maintain image size\n",
        "\n",
        "        # Max pooling layer (downsampling)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "        # Fully connected layer (flatten the output of the conv layers)\n",
        "        self.fc1 = nn.Linear(32 * 8 * 8, 128)  # Flattened size is 32 channels, 8x8 image\n",
        "        self.fc2 = nn.Linear(128, 10)  # Output layer for 10 classes in CIFAR-10 dataset\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply first convolutional layer and ReLU activation\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "\n",
        "        # Apply second convolutional layer and ReLU activation\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "\n",
        "        # Flatten the output before passing it into the fully connected layer\n",
        "        x = x.view(-1, 32 * 8 * 8)  # Flatten the tensor to shape (batch_size, 32*8*8)\n",
        "\n",
        "        # Pass through the first fully connected layer\n",
        "        x = torch.relu(self.fc1(x))\n",
        "\n",
        "        # Pass through the second fully connected layer (output layer)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Step 3: Instantiate the model, define the loss function, and the optimizer\n",
        "model = SimpleCNN()\n",
        "\n",
        "# Loss function (CrossEntropyLoss for multi-class classification)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer (Stochastic Gradient Descent with learning rate 0.001)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Step 4: Train the model\n",
        "num_epochs = 10  # Number of epochs (iterations through the entire dataset)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):  # Loop over the training data\n",
        "        inputs, labels = data\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass: compute predicted outputs by passing inputs to the model\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass: compute gradients of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Update the model's parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print statistics (every 100 mini-batches)\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:\n",
        "            print(f\"[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 100:.3f}\")\n",
        "            running_loss = 0.0\n",
        "\n",
        "print(\"Finished Training\")\n",
        "\n",
        "# Step 5: Test the model on the test set\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# Turn off gradients for testing\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        inputs, labels = data\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)  # Get the predicted class\n",
        "        total += labels.size(0)  # Total number of samples\n",
        "        correct += (predicted == labels).sum().item()  # Number of correct predictions\n",
        "\n",
        "print(f\"Accuracy of the network on the 10000 test images: {100 * correct / total:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hus4vBJoiLC2"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Step 1: Load and preprocess the CIFAR-10 dataset\n",
        "# Apply data augmentation (random horizontal flip and random crop)\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),  # Randomly flip images horizontally\n",
        "    transforms.RandomCrop(32, padding=4),  # Randomly crop images with padding\n",
        "    transforms.ToTensor(),  # Convert image to tensor\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize with mean and std deviation for RGB channels\n",
        "])\n",
        "\n",
        "# Download CIFAR-10 train and test datasets\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Create data loaders\n",
        "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "testloader = DataLoader(testset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Step 2: Define the improved CNN model\n",
        "class AdvancedCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AdvancedCNN, self).__init__()\n",
        "\n",
        "        # First convolutional layer\n",
        "        self.conv1 = nn.Conv2d(in_channels=3,  # Input channels (RGB)\n",
        "                               out_channels=32,  # Output channels (number of filters)\n",
        "                               kernel_size=3,  # Size of the convolutional kernel/filter\n",
        "                               stride=1,  # Step size for sliding the filter\n",
        "                               padding=1)  # Padding to maintain image size\n",
        "\n",
        "        # Batch normalization layer for the first convolutional layer\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "\n",
        "        # Second convolutional layer\n",
        "        self.conv2 = nn.Conv2d(in_channels=32,  # Input channels (from previous layer)\n",
        "                               out_channels=64,  # Output channels (number of filters)\n",
        "                               kernel_size=3,  # Size of the convolutional kernel/filter\n",
        "                               stride=1,  # Step size for sliding the filter\n",
        "                               padding=1)  # Padding to maintain image size\n",
        "\n",
        "        # Batch normalization layer for the second convolutional layer\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "\n",
        "        # Third convolutional layer\n",
        "        self.conv3 = nn.Conv2d(in_channels=64,  # Input channels (from previous layer)\n",
        "                               out_channels=128,  # Output channels (number of filters)\n",
        "                               kernel_size=3,  # Size of the convolutional kernel/filter\n",
        "                               stride=1,  # Step size for sliding the filter\n",
        "                               padding=1)  # Padding to maintain image size\n",
        "\n",
        "        # Max pooling layer (downsampling)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "        # Dropout layer (to avoid overfitting)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 256)  # Flattened size is 128 channels, 4x4 image after pooling\n",
        "        self.fc2 = nn.Linear(256, 10)  # Output layer for 10 classes in CIFAR-10 dataset\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply first convolutional layer, batch normalization, and ReLU activation\n",
        "        x = self.pool(torch.relu(self.bn1(self.conv1(x))))\n",
        "\n",
        "        # Apply second convolutional layer, batch normalization, and ReLU activation\n",
        "        x = self.pool(torch.relu(self.bn2(self.conv2(x))))\n",
        "\n",
        "        # Apply third convolutional layer and ReLU activation\n",
        "        x = self.pool(torch.relu(self.conv3(x)))\n",
        "\n",
        "        # Flatten the output before passing it into the fully connected layer\n",
        "        x = x.view(-1, 128 * 4 * 4)  # Flatten the tensor to shape (batch_size, 128*4*4)\n",
        "\n",
        "        # Pass through the first fully connected layer and apply dropout\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # Pass through the second fully connected layer (output layer)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Step 3: Instantiate the model, define the loss function, and the optimizer\n",
        "model = AdvancedCNN()\n",
        "\n",
        "# Loss function (CrossEntropyLoss for multi-class classification)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer (Adam optimizer for better performance in most cases)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Step 4: Learning rate scheduler\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)  # Reduce LR by a factor of 10 every 10 epochs\n",
        "\n",
        "# Step 5: Train the model\n",
        "num_epochs = 15  # Increased number of epochs for better training\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):  # Loop over the training data\n",
        "        inputs, labels = data\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass: compute predicted outputs by passing inputs to the model\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass: compute gradients of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Update the model's parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print statistics (every 100 mini-batches)\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:\n",
        "            print(f\"[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 100:.3f}\")\n",
        "            running_loss = 0.0\n",
        "\n",
        "    # Step the learning rate scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "print(\"Finished Training\")\n",
        "\n",
        "# Step 6: Test the model on the test set\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# Turn off gradients for testing\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        inputs, labels = data\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)  # Get the predicted class\n",
        "        total += labels.size(0)  # Total number of samples\n",
        "        correct += (predicted == labels).sum().item()  # Number of correct predictions\n",
        "\n",
        "print(f\"Accuracy of the network on the 10000 test images: {100 * correct / total:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LuaE4UlmFkhT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            root_dir (str): Root directory path.\n",
        "            transform (callable, optional): Optional transform to be applied on a sample.\n",
        "        \"\"\"\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        # List to store tuples of (image_path, label)\n",
        "        self.image_labels = []\n",
        "\n",
        "        # Get the class names from the subdirectory names\n",
        "        self.classes = sorted(entry.name for entry in os.scandir(root_dir) if entry.is_dir())\n",
        "        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(self.classes)}\n",
        "\n",
        "        # Traverse through each class directory and collect image paths and labels\n",
        "        for cls in self.classes:\n",
        "            cls_dir = os.path.join(root_dir, cls)\n",
        "            for root, _, files in os.walk(cls_dir):\n",
        "                for file in files:\n",
        "                    if self.is_image_file(file):\n",
        "                        path = os.path.join(root, file)\n",
        "                        self.image_labels.append((path, self.class_to_idx[cls]))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if idx < 0 or idx >= len(self):\n",
        "            raise IndexError(\"Index out of bounds\")\n",
        "\n",
        "        img_path, label = self.image_labels[idx]\n",
        "        image = Image.open(img_path).convert('RGB')  # Ensure image is in RGB format\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "    @staticmethod\n",
        "    def is_image_file(filename):\n",
        "        \"\"\"Check if a file is an image.\"\"\"\n",
        "        extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.gif']\n",
        "        return any(filename.lower().endswith(ext) for ext in extensions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PP_RFkujOFKP"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fu7CQJfzJkPn"
      },
      "outputs": [],
      "source": [
        "!unzip custom-dataset.zip -d ./"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZEu5fIsJunN"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
        "    transforms.ToTensor(),          # Convert PIL Image to Tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # Normalize with ImageNet means and stds\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "dataset = CustomImageDataset(root_dir='./custom-dataset', transform=transform)\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=4)\n",
        "\n",
        "for batch_idx, (images, labels) in enumerate(dataloader):\n",
        "    print(f'Batch {batch_idx + 1}')\n",
        "    print(f'Images shape: {images.shape}')\n",
        "    print(f'Labels: {labels}')\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iisUrbxwzdWX"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dto2oKSIv7-9"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoImageProcessor, ResNetForImageClassification\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset\n",
        "# dataset = load_dataset(\"huggingface/cats-image\")\n",
        "# dataset = load_dataset(\"AI-Lab-Makerere/beans\")\n",
        "dataset = load_dataset(\"RGurung/Animal_dataset\")\n",
        "dataset = load_dataset('imagefolder', data_dir=\"./custom-dataset\")\n",
        "\n",
        "# Display the dataset structure\n",
        "print(dataset)\n",
        "\n",
        "# Select an image from the test split\n",
        "image = dataset[\"train\"][\"image\"][5]\n",
        "\n",
        "# Load the image processor and model\n",
        "processor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-50\")\n",
        "model = ResNetForImageClassification.from_pretrained(\"microsoft/resnet-50\")\n",
        "\n",
        "# Preprocess the image\n",
        "inputs = processor(image, return_tensors=\"pt\")\n",
        "\n",
        "# Perform inference without tracking gradients\n",
        "with torch.no_grad():\n",
        "    logits = model(**inputs).logits\n",
        "\n",
        "# Get the predicted class index\n",
        "predicted_class_idx = logits.argmax(-1).item()\n",
        "\n",
        "# Retrieve the label corresponding to the predicted index\n",
        "predicted_label = model.config.id2label[predicted_class_idx]\n",
        "\n",
        "# Print the predicted class index and label\n",
        "print(f\"Predicted Class Index: {predicted_class_idx}\")\n",
        "print(f\"Predicted Label: {predicted_label}\")\n",
        "\n",
        "# Plot the image with the predicted label\n",
        "plt.figure(figsize=(8, 8))  # Set the figure size (optional)\n",
        "plt.imshow(image)\n",
        "plt.title(f\"Predicted Label: {predicted_label}\", fontsize=16)\n",
        "plt.axis('off')  # Hide the axis\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WI23KMzDg3V"
      },
      "outputs": [],
      "source": [
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXiYpX0QDFYa"
      },
      "outputs": [],
      "source": [
        "# 1. Import Necessary Libraries\n",
        "from transformers import (\n",
        "    AutoImageProcessor,\n",
        "    ResNetForImageClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torchvision.transforms import (\n",
        "    Compose,\n",
        "    Resize,\n",
        "    CenterCrop,\n",
        "    ToTensor,\n",
        "    Normalize,\n",
        "    RandomHorizontalFlip,\n",
        "    RandomRotation\n",
        ")\n",
        "import evaluate\n",
        "import torch.nn as nn\n",
        "\n",
        "# 2. Load the Beans Dataset\n",
        "dataset = load_dataset(\"AI-Lab-Makerere/beans\")\n",
        "\n",
        "# Display the dataset structure\n",
        "print(dataset)\n",
        "\n",
        "# Get the number of classes\n",
        "num_classes = dataset['train'].features['labels'].num_classes\n",
        "print(f\"Number of classes: {num_classes}\")\n",
        "\n",
        "# Display class names\n",
        "class_names = dataset['train'].features['labels'].names\n",
        "print(f\"Class names: {class_names}\")\n",
        "\n",
        "# 3. Define Image Transformations\n",
        "train_transforms = Compose([\n",
        "    Resize((224, 224)),\n",
        "    RandomHorizontalFlip(),\n",
        "    RandomRotation(15),\n",
        "    ToTensor(),\n",
        "    Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],  # ImageNet means\n",
        "        std=[0.229, 0.224, 0.225]    # ImageNet stds\n",
        "    )\n",
        "])\n",
        "\n",
        "validation_transforms = Compose([\n",
        "    Resize((224, 224)),\n",
        "    CenterCrop(224),\n",
        "    ToTensor(),\n",
        "    Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "# 4. Define the Preprocessing Function\n",
        "def preprocess_function(examples, split):\n",
        "    \"\"\"\n",
        "    Applies the appropriate transformations to the images based on the dataset split.\n",
        "\n",
        "    Args:\n",
        "        examples (dict): A batch of examples from the dataset.\n",
        "        split (str): The dataset split ('train', 'validation', 'test').\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary with the transformed images added under the key 'pixel_values'.\n",
        "    \"\"\"\n",
        "    images = examples['image']  # Assuming 'image' contains PIL Images\n",
        "    if split == 'train':\n",
        "        images = [train_transforms(image) for image in images]\n",
        "    else:\n",
        "        images = [validation_transforms(image) for image in images]\n",
        "    examples['pixel_values'] = images\n",
        "    return examples\n",
        "\n",
        "# 5. Apply Preprocessing to Each Split\n",
        "dataset['train'] = dataset['train'].map(\n",
        "    lambda examples: preprocess_function(examples, 'train'),\n",
        "    batched=True\n",
        ")\n",
        "dataset['validation'] = dataset['validation'].map(\n",
        "    lambda examples: preprocess_function(examples, 'validation'),\n",
        "    batched=True\n",
        ")\n",
        "dataset['test'] = dataset['test'].map(\n",
        "    lambda examples: preprocess_function(examples, 'test'),\n",
        "    batched=True\n",
        ")\n",
        "\n",
        "# 6. Set the Format for PyTorch\n",
        "dataset.set_format(\n",
        "    type='torch',\n",
        "    columns=['pixel_values', 'labels']\n",
        ")\n",
        "\n",
        "# 7. Load the Image Processor and Model with Fixed Parameters\n",
        "processor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-50\")\n",
        "\n",
        "model = ResNetForImageClassification.from_pretrained(\n",
        "    \"microsoft/resnet-50\",\n",
        "    num_labels=num_classes,  # Set the number of labels to match the dataset\n",
        "    id2label={str(i): label for i, label in enumerate(class_names)},\n",
        "    label2id={label: i for i, label in enumerate(class_names)},\n",
        "    ignore_mismatched_sizes=True  # Ignore size mismatches for the classifier layer\n",
        ")\n",
        "\n",
        "# Optional: Manually Replace the Classifier (if needed)\n",
        "# This step is generally handled by 'ignore_mismatched_sizes=True', but can be used for more control.\n",
        "# model.classifier = nn.Linear(in_features=2048, out_features=num_classes)\n",
        "\n",
        "# 8. Define Training Arguments with Fixed Parameters\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./resnet50-beans\",          # Output directory\n",
        "    per_device_train_batch_size=16,         # Batch size per device during training\n",
        "    per_device_eval_batch_size=16,          # Batch size for evaluation\n",
        "    num_train_epochs=10,                    # Total number of training epochs\n",
        "    learning_rate=5e-5,                     # Learning rate\n",
        "    eval_strategy=\"epoch\",                  # Evaluation strategy to adopt during training\n",
        "    save_strategy=\"epoch\",                  # Save checkpoint every epoch\n",
        "    logging_dir=\"./logs\",                   # Directory for storing logs\n",
        "    logging_steps=10,                       # Log every 10 steps\n",
        "    load_best_model_at_end=True,            # Load the best model when finished training\n",
        "    metric_for_best_model=\"accuracy\",       # Use accuracy to evaluate the best model\n",
        "    greater_is_better=True,                 # Whether the better metric is higher\n",
        "    report_to=\"none\",                       # Disable reporting to any tracking system (e.g., W&B)\n",
        "    save_total_limit=2                      # Limit the total amount of checkpoints. Deletes the older checkpoints.\n",
        ")\n",
        "\n",
        "# 9. Define Evaluation Metrics\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"\n",
        "    Computes accuracy metrics.\n",
        "\n",
        "    Args:\n",
        "        eval_pred (tuple): Tuple containing predictions and labels.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary with accuracy.\n",
        "    \"\"\"\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return accuracy.compute(predictions=predictions, references=labels)\n",
        "\n",
        "# 10. Initialize the Trainer Without Using 'tokenizer'\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset['train'],\n",
        "    eval_dataset=dataset['validation'],\n",
        "    compute_metrics=compute_metrics,\n",
        "    # Removed 'tokenizer=processor' to avoid FutureWarning\n",
        ")\n",
        "\n",
        "# 11. Fine-Tune the Model\n",
        "trainer.train()\n",
        "\n",
        "# 12. Evaluate the Model on the Test Set\n",
        "results = trainer.evaluate(dataset['test'])\n",
        "print(f\"Test Accuracy: {results['eval_accuracy']:.4f}\")\n",
        "\n",
        "# 13. Save the Fine-Tuned Model and Processor\n",
        "model.save_pretrained(\"./resnet50-beans-finetuned\")\n",
        "processor.save_pretrained(\"./resnet50-beans-finetuned\")\n",
        "\n",
        "# 14. Define the Prediction Function\n",
        "def predict(image):\n",
        "    \"\"\"\n",
        "    Predicts the label of a given image using the fine-tuned model.\n",
        "\n",
        "    Args:\n",
        "        image (PIL.Image.Image): The input image.\n",
        "\n",
        "    Returns:\n",
        "        str: The predicted label.\n",
        "    \"\"\"\n",
        "    inputs = processor(images=image, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits\n",
        "    predicted_class_idx = logits.argmax(-1).item()\n",
        "    predicted_label = model.config.id2label[str(predicted_class_idx)]\n",
        "    return predicted_label\n",
        "\n",
        "# 15. Example Prediction and Visualization\n",
        "# Select an image from the test set\n",
        "test_image = dataset['test'][0]['image']  # This is a PIL Image\n",
        "\n",
        "# Make a prediction\n",
        "predicted_label = predict(test_image)\n",
        "print(f\"Predicted Label: {predicted_label}\")\n",
        "\n",
        "# Plot the image with the predicted label\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(test_image)\n",
        "plt.title(f\"Predicted Label: {predicted_label}\", fontsize=16)\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6fZwyGT_IxS"
      },
      "outputs": [],
      "source": [
        "# 1. Import Necessary Libraries\n",
        "from transformers import (\n",
        "    AutoImageProcessor,\n",
        "    ResNetForImageClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torchvision.transforms import (\n",
        "    Compose,\n",
        "    Resize,\n",
        "    CenterCrop,\n",
        "    ToTensor,\n",
        "    Normalize,\n",
        "    RandomHorizontalFlip,\n",
        "    RandomRotation\n",
        ")\n",
        "import evaluate\n",
        "import torch.nn as nn\n",
        "\n",
        "# 2. Load the Beans Dataset\n",
        "dataset = load_dataset(\"AI-Lab-Makerere/beans\")\n",
        "\n",
        "# Display the dataset structure\n",
        "print(dataset)\n",
        "\n",
        "# Get the number of classes\n",
        "num_classes = dataset['train'].features['labels'].num_classes\n",
        "print(f\"Number of classes: {num_classes}\")\n",
        "\n",
        "# Display class names\n",
        "class_names = dataset['train'].features['labels'].names\n",
        "print(f\"Class names: {class_names}\")\n",
        "\n",
        "# 3. Define Image Transformations\n",
        "train_transforms = Compose([\n",
        "    Resize((224, 224)),\n",
        "    RandomHorizontalFlip(),\n",
        "    RandomRotation(15),\n",
        "    ToTensor(),\n",
        "    Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],  # ImageNet means\n",
        "        std=[0.229, 0.224, 0.225]    # ImageNet stds\n",
        "    )\n",
        "])\n",
        "\n",
        "validation_transforms = Compose([\n",
        "    Resize((224, 224)),\n",
        "    CenterCrop(224),\n",
        "    ToTensor(),\n",
        "    Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "# 4. Define the Preprocessing Function\n",
        "def preprocess_function(examples, split):\n",
        "    \"\"\"\n",
        "    Applies the appropriate transformations to the images based on the dataset split.\n",
        "\n",
        "    Args:\n",
        "        examples (dict): A batch of examples from the dataset.\n",
        "        split (str): The dataset split ('train', 'validation', 'test').\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary with the transformed images added under the key 'pixel_values'.\n",
        "    \"\"\"\n",
        "    images = examples['image']  # Assuming 'image' contains PIL Images\n",
        "    if split == 'train':\n",
        "        images = [train_transforms(image) for image in images]\n",
        "    else:\n",
        "        images = [validation_transforms(image) for image in images]\n",
        "    examples['pixel_values'] = images\n",
        "    return examples\n",
        "\n",
        "# 5. Apply Preprocessing to Each Split\n",
        "dataset['train'] = dataset['train'].map(\n",
        "    lambda examples: preprocess_function(examples, 'train'),\n",
        "    batched=True\n",
        ")\n",
        "dataset['validation'] = dataset['validation'].map(\n",
        "    lambda examples: preprocess_function(examples, 'validation'),\n",
        "    batched=True\n",
        ")\n",
        "dataset['test'] = dataset['test'].map(\n",
        "    lambda examples: preprocess_function(examples, 'test'),\n",
        "    batched=True\n",
        ")\n",
        "\n",
        "# 6. Set the Format for PyTorch\n",
        "dataset.set_format(\n",
        "    type='torch',\n",
        "    columns=['pixel_values', 'labels']\n",
        ")\n",
        "\n",
        "# 7. Load the Image Processor and Model with Fixed Parameters\n",
        "processor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-50\")\n",
        "\n",
        "model = ResNetForImageClassification.from_pretrained(\"microsoft/resnet-50\",)\n",
        "\n",
        "# Manually Replace the Classifier\n",
        "model.fc = nn.Linear(in_features=2048, out_features=num_classes)\n",
        "\n",
        "model.config.id2label = {i: label for i, label in enumerate(class_names)}\n",
        "model.config.label2id = {label: i for i, label in enumerate(class_names)}\n",
        "\n",
        "# 8. Freeze All Layers Except the Last Layer\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False  # Freeze all layers\n",
        "\n",
        "# Unfreeze the last layer (classifier layer)\n",
        "for param in model.classifier.parameters():\n",
        "    param.requires_grad = True  # Fine-tune the last layer\n",
        "\n",
        "# 9. Define Training Arguments with Fixed Parameters\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./resnet50-beans\",          # Output directory\n",
        "    per_device_train_batch_size=16,         # Batch size per device during training\n",
        "    per_device_eval_batch_size=16,          # Batch size for evaluation\n",
        "    num_train_epochs=10,                    # Total number of training epochs\n",
        "    learning_rate=5e-5,                     # Learning rate\n",
        "    eval_strategy=\"epoch\",                  # Evaluation strategy to adopt during training\n",
        "    save_strategy=\"epoch\",                  # Save checkpoint every epoch\n",
        "    logging_dir=\"./logs\",                   # Directory for storing logs\n",
        "    logging_steps=10,                       # Log every 10 steps\n",
        "    load_best_model_at_end=True,            # Load the best model when finished training\n",
        "    metric_for_best_model=\"accuracy\",       # Use accuracy to evaluate the best model\n",
        "    greater_is_better=True,                 # Whether the better metric is higher\n",
        "    report_to=\"none\",                       # Disable reporting to any tracking system (e.g., W&B)\n",
        "    save_total_limit=2                      # Limit the total amount of checkpoints. Deletes the older checkpoints.\n",
        ")\n",
        "\n",
        "# 10. Define Evaluation Metrics\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"\n",
        "    Computes accuracy metrics.\n",
        "\n",
        "    Args:\n",
        "        eval_pred (tuple): Tuple containing predictions and labels.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary with accuracy.\n",
        "    \"\"\"\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return accuracy.compute(predictions=predictions, references=labels)\n",
        "\n",
        "# 11. Initialize the Trainer Without Using 'tokenizer'\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset['train'],\n",
        "    eval_dataset=dataset['validation'],\n",
        "    compute_metrics=compute_metrics,\n",
        "    # Removed 'tokenizer=processor' to avoid FutureWarning\n",
        ")\n",
        "\n",
        "# 12. Fine-Tune the Model\n",
        "trainer.train()\n",
        "\n",
        "# 13. Evaluate the Model on the Test Set\n",
        "results = trainer.evaluate(dataset['test'])\n",
        "print(f\"Test Accuracy: {results['eval_accuracy']:.4f}\")\n",
        "\n",
        "# 14. Save the Fine-Tuned Model and Processor\n",
        "model.save_pretrained(\"./resnet50-beans-finetuned\")\n",
        "processor.save_pretrained(\"./resnet50-beans-finetuned\")\n",
        "\n",
        "# 15. Define the Prediction Function\n",
        "def predict(image):\n",
        "    \"\"\"\n",
        "    Predicts the label of a given image using the fine-tuned model.\n",
        "\n",
        "    Args:\n",
        "        image (PIL.Image.Image): The input image.\n",
        "\n",
        "    Returns:\n",
        "        str: The predicted label.\n",
        "    \"\"\"\n",
        "    inputs = processor(images=image, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits\n",
        "    predicted_class_idx = logits.argmax(-1).item()\n",
        "    predicted_label = model.config.id2label[str(predicted_class_idx)]\n",
        "    return predicted_label\n",
        "\n",
        "# 16. Example Prediction and Visualization\n",
        "# Select an image from the test set\n",
        "test_image = dataset['test'][0]['image']  # This is a PIL Image\n",
        "\n",
        "# Make a prediction\n",
        "predicted_label = predict(test_image)\n",
        "print(f\"Predicted Label: {predicted_label}\")\n",
        "\n",
        "# Plot the image with the predicted label\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(test_image)\n",
        "plt.title(f\"Predicted Label: {predicted_label}\", fontsize=16)\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_HMdK0lEg2z"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
